{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5697731b-83a2-4da5-beb2-90698a82969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in d:\\virtual-tryon\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in d:\\virtual-tryon\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: smplx in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.1.28)\n",
      "Requirement already satisfied: numpy>=1.16.2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from smplx) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.0.1.post2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from smplx) (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.1.post2->smplx) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jinja2->torch>=1.0.1.post2->smplx) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in d:\\virtual-tryon\\.venv\\lib\\site-packages (4.12.0.88)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trimesh in d:\\virtual-tryon\\.venv\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from trimesh) (2.2.6)\n",
      "Requirement already satisfied: pyrender in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.1.45)\n",
      "Requirement already satisfied: freetype-py in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.5.1)\n",
      "Requirement already satisfied: imageio in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.37.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (3.5)\n",
      "Requirement already satisfied: numpy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.2.6)\n",
      "Requirement already satisfied: Pillow in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (10.1.0)\n",
      "Requirement already satisfied: pyglet>=1.4.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.1.8)\n",
      "Requirement already satisfied: PyOpenGL==3.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (3.1.0)\n",
      "Requirement already satisfied: scipy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (1.16.1)\n",
      "Requirement already satisfied: six in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (1.17.0)\n",
      "Requirement already satisfied: trimesh in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (4.8.1)\n",
      "Requirement already satisfied: matplotlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: pyopengl in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: mediapipe in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: jaxlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: matplotlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (3.10.6)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.2.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\virtual-tryon\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (1.16.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyopengl in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pyopengl_accelerate in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install smplx\n",
    "!pip install opencv-python\n",
    "!pip install trimesh\n",
    "!pip install pyrender\n",
    "!pip install matplotlib\n",
    "!pip install pyopengl\n",
    "!pip install mediapipe\n",
    "!pip install pyopengl pyopengl_accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309def15-b202-4bf3-b6ec-840917084608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching pyrender viewer... (press ESC to quit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Viewer=(width=800, height=800)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import smplx\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "\n",
    "# ========== Load SMPL model ==========\n",
    "MODEL_PATH = \"./SMPL_models\"   # <-- replace with the folder containing smpl.pkl\n",
    "smpl = smplx.SMPL(model_path=MODEL_PATH, gender=\"NEUTRAL\").to(\"cpu\")\n",
    "\n",
    "# Shape and pose parameters\n",
    "betas = torch.zeros([1, 10], device=\"cpu\")\n",
    "body_pose = torch.zeros([1, 69], device=\"cpu\")\n",
    "\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "mesh_pr = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "# ========== Scene ==========\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh_pr)\n",
    "\n",
    "# Add camera\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "camera_pose = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, -0.5],   # move up a bit\n",
    "    [0, 0, 1, 2.5],    # move back a bit\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# Add light\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=np.eye(4))\n",
    "\n",
    "# ========== Viewer ==========\n",
    "print(\"Launching pyrender viewer... (press ESC to quit)\")\n",
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(800, 800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f37e7e2-4f6a-4578-92c6-b6b3917f7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import cv2\n",
    "\n",
    "from smplx import SMPL\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load SMPL model (T-pose)\n",
    "# -------------------------------\n",
    "smpl_model_path = \"./smpl_models\"  # adjust to your path\n",
    "smpl = SMPL(model_path=smpl_model_path, gender='NEUTRAL')\n",
    "\n",
    "# Zero pose & shape → T-pose\n",
    "betas = torch.zeros([1, 10], dtype=torch.float32)\n",
    "body_pose = torch.zeros([1, 69], device=\"cpu\")\n",
    "\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Render SMPL (offscreen)\n",
    "# -------------------------------\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "pyr_mesh = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "scene = pyrender.Scene(bg_color=[255, 255, 255, 255], ambient_light=[0.8, 0.8, 0.8])\n",
    "scene.add(pyr_mesh)\n",
    "\n",
    "# ---- Add Camera ----\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "cam_pose = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, -0.5],   # move camera up a bit\n",
    "    [0.0, 0.0, 1.0, 2.5],    # move camera away from SMPL\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "scene.add(camera, pose=cam_pose)\n",
    "\n",
    "# ---- Add Light ----\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=cam_pose)\n",
    "\n",
    "# ---- Offscreen Renderer ----\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=512, viewport_height=512)\n",
    "color, depth = renderer.render(scene)\n",
    "renderer.delete()\n",
    "\n",
    "# Convert to OpenCV format\n",
    "smpl_img = cv2.cvtColor(color, cv2.COLOR_RGBA2BGRA)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load 2D shirt\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Define torso region (approx)\n",
    "# -------------------------------\n",
    "shift_up = 88\n",
    "h, w, _ = smpl_img.shape\n",
    "x1, y1 = int(w*0.3), int(h*0.35) - shift_up  # left shoulder\n",
    "x2, y2 = int(w*0.7), int(h*0.65) - shift_up  # right hip\n",
    "\n",
    "sh_h, sh_w = shirt_img.shape[:2]\n",
    "torso_width  = (x2 - x1) \n",
    "torso_height = (y2 - y1)\n",
    "scale = min(torso_width / sh_w, torso_height / sh_h)\n",
    "old_w = int(sh_w * scale)\n",
    "old_h = int(sh_h * scale)\n",
    "\n",
    "shrink_factor = 0.72\n",
    "new_w = int(old_w * shrink_factor)\n",
    "new_h = int(old_h * shrink_factor)\n",
    "\n",
    "\n",
    "resized_shirt = cv2.resize(shirt_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Overlay shirt on SMPL\n",
    "# -------------------------------\n",
    "offset_x = x1 + (torso_width - new_w) // 2\n",
    "offset_y = y1 + (torso_height - new_h) // 2\n",
    "\n",
    "overlay = smpl_img.copy()\n",
    "for y in range(new_h):\n",
    "    for x in range(new_w):\n",
    "        if resized_shirt[y, x, 3] > 0:  # alpha\n",
    "            overlay[offset_y+y, offset_x+x, :3] = resized_shirt[y, x, :3]\n",
    "\n",
    "# -------------------------------\n",
    "# 3b. Load 2D pants\n",
    "# -------------------------------\n",
    "pant_img = cv2.imread(\"./database/cargo.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 4b. Define hip/leg region (approx)\n",
    "# -------------------------------\n",
    "shift_up = 95\n",
    "x1_p, y1_p = int(w*0.35), int(h*0.55) - shift_up # left hip\n",
    "x2_p, y2_p = int(w*0.65), int(h*0.85) - shift_up # right thigh\n",
    "\n",
    "pant_h, pant_w = pant_img.shape[:2]\n",
    "pant_width  = (x2_p - x1_p)\n",
    "pant_height = (y2_p - y1_p)\n",
    "\n",
    "# Make pant a bit wider\n",
    "scale_w = 1.20 * (pant_width / pant_w)  # 20% wider\n",
    "scale_h = pant_height / pant_h         # keep vertical scale the same\n",
    "\n",
    "new_w_p = int(pant_w * scale_w)\n",
    "new_h_p = int(pant_h * scale_h)\n",
    "\n",
    "resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "# shrink_factor = 1.00\n",
    "# new_w_p = int(old_w_p * shrink_factor)\n",
    "# new_h_p = int(old_h_p * shrink_factor)\n",
    "\n",
    "# resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# -------------------------------\n",
    "# 5b. Overlay pants on SMPL\n",
    "# -------------------------------\n",
    "offset_x_p = x1_p + (pant_width - new_w_p) // 2 \n",
    "offset_y_p = y1_p + (pant_height - new_h_p) // 2 + 25\n",
    "\n",
    "for y in range(new_h_p):\n",
    "    for x in range(new_w_p):\n",
    "        if resized_pant[y, x, 3] > 0:  # alpha\n",
    "            overlay[offset_y_p+y, offset_x_p+x, :3] = resized_pant[y, x, :3]\n",
    "\n",
    "# -------------------------------\n",
    "# 6b. Show result\n",
    "# -------------------------------\n",
    "cv2.imshow(\"SMPL + Shirt + Pants\", overlay)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9831338e-7ff1-4f20-b460-c4d87dcf302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import cv2\n",
    "from smplx import SMPL\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load SMPL model (T-pose)\n",
    "# -------------------------------\n",
    "smpl_model_path = \"./smpl_models\"  # adjust to your path\n",
    "smpl = SMPL(model_path=smpl_model_path, gender='NEUTRAL')\n",
    "\n",
    "betas = torch.zeros([1, 10], dtype=torch.float32)\n",
    "body_pose = torch.zeros([1, 69], device=\"cpu\")\n",
    "\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "joints = output.joints[0].detach().cpu().numpy()\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Render SMPL (offscreen)\n",
    "# -------------------------------\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "pyr_mesh = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "scene = pyrender.Scene(bg_color=[255, 255, 255, 255], ambient_light=[0.8, 0.8, 0.8])\n",
    "scene.add(pyr_mesh)\n",
    "\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "cam_pose = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, -0.5],\n",
    "    [0.0, 0.0, 1.0, 2.5],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "scene.add(camera, pose=cam_pose)\n",
    "\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=cam_pose)\n",
    "\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=512, viewport_height=512)\n",
    "color, depth = renderer.render(scene)\n",
    "renderer.delete()\n",
    "\n",
    "# Convert to OpenCV BGRA\n",
    "smpl_img = cv2.cvtColor(color, cv2.COLOR_RGBA2BGRA)\n",
    "H, W = smpl_img.shape[:2]\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: Project 3D → 2D\n",
    "# -------------------------------\n",
    "def project_to_image(point_3d, camera_pose, camera, W, H):\n",
    "    point_h = np.append(point_3d, 1)\n",
    "    cam_point = np.linalg.inv(camera_pose) @ point_h\n",
    "    x = cam_point[0] / cam_point[2]\n",
    "    y = cam_point[1] / cam_point[2]\n",
    "    f = 0.5 * H / np.tan(camera.yfov / 2)\n",
    "    u = int(W/2 + x*f)\n",
    "    v = int(H/2 - y*f)\n",
    "    return u, v\n",
    "\n",
    "def clamp(val, min_val, max_val):\n",
    "    return max(min_val, min(val, max_val))\n",
    "\n",
    "def overlay_rgba(background, overlay_img, x, y):\n",
    "    bh, bw = background.shape[:2]\n",
    "    oh, ow = overlay_img.shape[:2]\n",
    "    result = background.copy()\n",
    "\n",
    "    for i in range(oh):\n",
    "        for j in range(ow):\n",
    "            yy, xx = y + i, x + j\n",
    "            if 0 <= yy < bh and 0 <= xx < bw:\n",
    "                if overlay_img.shape[2] == 4:\n",
    "                    alpha = overlay_img[i, j, 3] / 255.0\n",
    "                else:\n",
    "                    alpha = 1.0\n",
    "                if alpha > 0:\n",
    "                    result[yy, xx, :3] = (\n",
    "                        alpha * overlay_img[i, j, :3] +\n",
    "                        (1 - alpha) * result[yy, xx, :3]\n",
    "                    )\n",
    "    return result\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load 2D shirt & pants\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "pant_img  = cv2.imread(\"./database/cargo.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Get SMPL joints → 2D\n",
    "# -------------------------------\n",
    "joint_indices = {\n",
    "    \"left_shoulder\": 30,\n",
    "    \"right_shoulder\": 33,\n",
    "    \"left_hip\": 4,\n",
    "    \"right_hip\": 5,\n",
    "    \"left_knee\": 1,\n",
    "    \"right_knee\": 2,\n",
    "    \"left_toe\": 13,\n",
    "    \"right_toe\": 14\n",
    "}\n",
    "\n",
    "joint_2d = {}\n",
    "for name, idx in joint_indices.items():\n",
    "    u, v = project_to_image(joints[idx], cam_pose, camera, W, H)\n",
    "    joint_2d[name] = (clamp(u, 0, W-1), clamp(v, 0, H-1))\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Auto-fit shirt\n",
    "# -------------------------------\n",
    "l_sh, r_sh = joint_2d[\"left_shoulder\"], joint_2d[\"right_shoulder\"]\n",
    "l_hip, r_hip = joint_2d[\"left_hip\"], joint_2d[\"right_hip\"]\n",
    "\n",
    "torso_width  = abs(r_sh[0] - l_sh[0])\n",
    "torso_height = abs(((l_hip[1] + r_hip[1]) // 2) - l_sh[1])\n",
    "\n",
    "sh_h, sh_w = shirt_img.shape[:2]\n",
    "scale_sh = min(torso_width / sh_w, torso_height / sh_h) * 1.5\n",
    "resized_shirt = cv2.resize(shirt_img, (int(sh_w*scale_sh), int(sh_h*scale_sh)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "offset_x = int((l_sh[0] + r_sh[0]) // 2 - resized_shirt.shape[1] // 2)\n",
    "offset_y = l_sh[1]\n",
    "overlay = overlay_rgba(smpl_img, resized_shirt, offset_x, offset_y)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Auto-fit pants\n",
    "# -------------------------------\n",
    "pant_width  = abs(r_hip[0] - l_hip[0])\n",
    "pant_height = abs(((joint_2d[\"left_knee\"][1] + joint_2d[\"right_knee\"][1]) // 2) - l_hip[1])\n",
    "\n",
    "pant_h, pant_w = pant_img.shape[:2]\n",
    "scale_pant_w = pant_width / pant_w * 1.3\n",
    "scale_pant_h = pant_height / pant_h * 1.2\n",
    "new_w_p = int(pant_w * scale_pant_w)\n",
    "new_h_p = int(pant_h * scale_pant_h)\n",
    "resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "offset_x_p = int((l_hip[0] + r_hip[0]) // 2 - resized_pant.shape[1] // 2)\n",
    "offset_y_p = l_hip[1]\n",
    "overlay = overlay_rgba(overlay, resized_pant, offset_x_p, offset_y_p)\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Draw joint markers\n",
    "# -------------------------------\n",
    "for name, (u, v) in joint_2d.items():\n",
    "    cv2.circle(overlay, (u, v), 5, (0, 0, 255), -1)   # red dot\n",
    "    cv2.putText(overlay, name, (u+5, v-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Show result\n",
    "# -------------------------------\n",
    "cv2.imshow(\"SMPL + Auto Shirt + Pants + Joints\", overlay)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d90342-b389-4e0b-9f7b-9237a32adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Load clothes (with transparency)\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "pant_img  = cv2.imread(\"./database/pant.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if shirt_img is None or pant_img is None:\n",
    "    raise FileNotFoundError(\"Shirt or pant image not found\")\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: Alpha overlay\n",
    "# -------------------------------\n",
    "def overlay_rgba(background, overlay_img, x, y):\n",
    "    bh, bw = background.shape[:2]\n",
    "    oh, ow = overlay_img.shape[:2]\n",
    "\n",
    "    # ✅ Handle negative offsets\n",
    "    if x < 0:\n",
    "        overlay_img = overlay_img[:, -x:]\n",
    "        ow = overlay_img.shape[1]\n",
    "        x = 0\n",
    "    if y < 0:\n",
    "        overlay_img = overlay_img[-y:, :]\n",
    "        oh = overlay_img.shape[0]\n",
    "        y = 0\n",
    "\n",
    "    if x >= bw or y >= bh:\n",
    "        return background\n",
    "\n",
    "    # Clip overlay if it goes outside frame\n",
    "    if x + ow > bw:\n",
    "        ow = bw - x\n",
    "        overlay_img = overlay_img[:, :ow]\n",
    "    if y + oh > bh:\n",
    "        oh = bh - y\n",
    "        overlay_img = overlay_img[:oh]\n",
    "\n",
    "    if ow <= 0 or oh <= 0:\n",
    "        return background\n",
    "\n",
    "    overlay_img = overlay_img.astype(float)\n",
    "    background_crop = background[y:y+oh, x:x+ow].astype(float)\n",
    "\n",
    "    if overlay_img.shape[2] == 4:\n",
    "        alpha = overlay_img[:, :, 3] / 255.0\n",
    "        alpha = np.stack([alpha]*3, axis=-1)\n",
    "    else:\n",
    "        alpha = np.ones_like(overlay_img[:, :, :3])\n",
    "\n",
    "    blended = alpha * overlay_img[:, :, :3] + (1 - alpha) * background_crop\n",
    "    background[y:y+oh, x:x+ow] = blended.astype(np.uint8)\n",
    "    return background\n",
    "\n",
    "# -------------------------------\n",
    "# Initialize MediaPipe Pose\n",
    "# -------------------------------\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    enable_segmentation=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# -------------------------------\n",
    "# Webcam Loop\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        lm = results.pose_landmarks.landmark\n",
    "\n",
    "        # Get key joints\n",
    "        l_shoulder = (int(lm[11].x * w), int(lm[11].y * h))\n",
    "        r_shoulder = (int(lm[12].x * w), int(lm[12].y * h))\n",
    "        l_hip      = (int(lm[23].x * w), int(lm[23].y * h))\n",
    "        r_hip      = (int(lm[24].x * w), int(lm[24].y * h))\n",
    "        l_knee     = (int(lm[25].x * w), int(lm[25].y * h))\n",
    "        r_knee     = (int(lm[26].x * w), int(lm[26].y * h))\n",
    "        l_ankle    = (int(lm[27].x * w), int(lm[27].y * h))\n",
    "        r_ankle    = (int(lm[28].x * w), int(lm[28].y * h))\n",
    "\n",
    "        # ---- SHIRT ----\n",
    "        torso_width  = abs(r_shoulder[0] - l_shoulder[0])\n",
    "        torso_height = abs(((l_hip[1] + r_hip[1]) // 2) - ((l_shoulder[1] + r_shoulder[1]) // 2))\n",
    "\n",
    "        sh_h, sh_w = shirt_img.shape[:2]\n",
    "        # ✅ Auto scaling: match detected torso + 15% margin\n",
    "        target_sh_w = int(torso_width * 1.15)\n",
    "        target_sh_h = int(torso_height * 1.15)\n",
    "\n",
    "        if target_sh_w > 0 and target_sh_h > 0:\n",
    "            resized_shirt = cv2.resize(shirt_img, (target_sh_w, target_sh_h))\n",
    "            offset_x = int((l_shoulder[0] + r_shoulder[0]) // 2 - resized_shirt.shape[1] // 2)\n",
    "            offset_y = min(l_shoulder[1], r_shoulder[1]) - int(resized_shirt.shape[0]*0.1)\n",
    "            frame = overlay_rgba(frame, resized_shirt, offset_x, offset_y)\n",
    "\n",
    "        # ---- PANTS ---- (modified to use ankles instead of knees)\n",
    "        pant_width  = abs(r_hip[0] - l_hip[0])\n",
    "        pant_height = abs(((l_ankle[1] + r_ankle[1]) // 2) - ((l_hip[1] + r_hip[1]) // 2))\n",
    "\n",
    "        p_h, p_w = pant_img.shape[:2]\n",
    "        # ✅ Auto scaling: match detected lower body (hip to ankle) + 10% margin\n",
    "        target_p_w = int(pant_width * 1.10)\n",
    "        target_p_h = int(pant_height * 1.20)\n",
    "\n",
    "        if target_p_w > 0 and target_p_h > 0:\n",
    "            resized_pant = cv2.resize(pant_img, (target_p_w, target_p_h))\n",
    "            offset_x_p = int((l_hip[0] + r_hip[0]) // 2 - resized_pant.shape[1] // 2)\n",
    "            offset_y_p = min(l_hip[1], r_hip[1]) - int(resized_pant.shape[0]*0.05)\n",
    "            frame = overlay_rgba(frame, resized_pant, offset_x_p, offset_y_p)\n",
    "\n",
    "        # Debug markers (hips, knees, ankles etc.)\n",
    "        for pt in [l_shoulder, r_shoulder, l_hip, r_hip, l_knee, r_knee, l_ankle, r_ankle]:\n",
    "            cv2.circle(frame, pt, 5, (0,0,255), -1)\n",
    "\n",
    "    cv2.imshow(\"Realtime Virtual Try-On\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700b98d0-d8a8-44e2-a3fb-f514e04517ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# User Input: Select Two Clothes\n",
    "# -------------------------------\n",
    "top_type = \"shirt\"    # choose from: \"shirt\", \"fullsleeve\"\n",
    "top_path = \"./database/fullsleeve.png\"  \n",
    "\n",
    "bottom_type = \"pant\"  # choose from: \"pant\", \"skirt\"\n",
    "bottom_path = \"./database/pant.png\"\n",
    "\n",
    "top_img = cv2.imread(top_path, cv2.IMREAD_UNCHANGED)\n",
    "bottom_img = cv2.imread(bottom_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if top_img is None:\n",
    "    raise FileNotFoundError(f\"❌ Top cloth not found at {top_path}\")\n",
    "if bottom_img is None:\n",
    "    raise FileNotFoundError(f\"❌ Bottom cloth not found at {bottom_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Mediapipe Pose\n",
    "# -------------------------------\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "landmark_names = {\n",
    "    \"l_shoulder\": 11, \"r_shoulder\": 12,\n",
    "    \"l_hip\": 23, \"r_hip\": 24,\n",
    "    \"l_ankle\": 27, \"r_ankle\": 28,\n",
    "    \"l_wrist\": 15, \"r_wrist\": 16,\n",
    "    \"l_toe\": 31, \"r_toe\": 32\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: overlay transparent image\n",
    "# -------------------------------\n",
    "def overlay_transparent(background, overlay, x, y):\n",
    "    h, w = overlay.shape[:2]\n",
    "    if x >= background.shape[1] or y >= background.shape[0]:\n",
    "        return background\n",
    "    if x < 0:\n",
    "        overlay = overlay[:, -x:]; w = overlay.shape[1]; x = 0\n",
    "    if y < 0:\n",
    "        overlay = overlay[-y:, :]; h = overlay.shape[0]; y = 0\n",
    "    if x + w > background.shape[1]:\n",
    "        w = background.shape[1] - x; overlay = overlay[:, :w]\n",
    "    if y + h > background.shape[0]:\n",
    "        h = background.shape[0] - y; overlay = overlay[:h, :]\n",
    "    if overlay.shape[2] < 4:\n",
    "        return background\n",
    "\n",
    "    overlay_img = overlay[:, :, :3]\n",
    "    mask = overlay[:, :, 3:] / 255.0\n",
    "    roi = background[y:y+h, x:x+w]\n",
    "    if roi.shape[:2] != overlay_img.shape[:2]:\n",
    "        return background\n",
    "    blended = (1.0 - mask) * roi + mask * overlay_img\n",
    "    background[y:y+h, x:x+w] = blended.astype(np.uint8)\n",
    "    return background\n",
    "\n",
    "# -------------------------------\n",
    "# Cloth Placement\n",
    "# -------------------------------\n",
    "def place_cloth(frame, cloth_img, cloth_type, get_point):\n",
    "    if cloth_img is None:\n",
    "        return frame\n",
    "\n",
    "    if cloth_type == \"pant\":\n",
    "        # Hips → Toes\n",
    "        l_hip, r_hip = get_point(\"l_hip\"), get_point(\"r_hip\")\n",
    "        l_toe, r_toe = get_point(\"l_toe\"), get_point(\"r_toe\")\n",
    "        hip_w = np.linalg.norm(np.array(r_hip) - np.array(l_hip))\n",
    "        leg_h = np.linalg.norm(np.array(l_toe) - np.array(l_hip))\n",
    "        new_w = int(hip_w * 2.2)\n",
    "        new_h = int(leg_h * 1.05)\n",
    "        resized = cv2.resize(cloth_img, (new_w, new_h))\n",
    "        cx = int((l_hip[0] + r_hip[0]) / 2 - new_w / 2)\n",
    "        cy = int(min(l_hip[1], r_hip[1]))\n",
    "        return overlay_transparent(frame, resized, cx, cy)\n",
    "\n",
    "    elif cloth_type == \"skirt\":\n",
    "        # Only Hips\n",
    "        l_hip, r_hip = get_point(\"l_hip\"), get_point(\"r_hip\")\n",
    "        hip_w = np.linalg.norm(np.array(r_hip) - np.array(l_hip))\n",
    "        new_w = int(hip_w * 2.2)\n",
    "        new_h = int(hip_w * 2.0)  # approximate skirt length\n",
    "        resized = cv2.resize(cloth_img, (new_w, new_h))\n",
    "        cx = int((l_hip[0] + r_hip[0]) / 2 - new_w / 2)\n",
    "        cy = int(min(l_hip[1], r_hip[1]))\n",
    "        return overlay_transparent(frame, resized, cx, cy)\n",
    "\n",
    "    elif cloth_type == \"shirt\":\n",
    "        # Only Shoulders\n",
    "        l_sh, r_sh = get_point(\"l_shoulder\"), get_point(\"r_shoulder\")\n",
    "        shoulder_w = np.linalg.norm(np.array(r_sh) - np.array(l_sh))\n",
    "        new_w = int(shoulder_w * 2.0)\n",
    "        new_h = int(shoulder_w * 2.2)  # torso length approx\n",
    "        resized = cv2.resize(cloth_img, (new_w, new_h))\n",
    "        cx = int((l_sh[0] + r_sh[0]) / 2 - new_w / 2)\n",
    "        cy = int(min(l_sh[1], r_sh[1])) - int(new_h * 0.1)\n",
    "        return overlay_transparent(frame, resized, cx, cy)\n",
    "\n",
    "    elif cloth_type == \"fullsleeve\":\n",
    "        # Same logic as shirt (overlay properly on bottom)\n",
    "        l_sh, r_sh = get_point(\"l_shoulder\"), get_point(\"r_shoulder\")\n",
    "        shoulder_w = np.linalg.norm(np.array(r_sh) - np.array(l_sh))\n",
    "        new_w = int(shoulder_w * 2.0)\n",
    "        new_h = int(shoulder_w * 2.2)  # torso length approx\n",
    "        resized = cv2.resize(cloth_img, (new_w, new_h))\n",
    "        cx = int((l_sh[0] + r_sh[0]) / 2 - new_w / 2)\n",
    "        cy = int(min(l_sh[1], r_sh[1])) - int(new_h * 0.1)\n",
    "        return overlay_transparent(frame, resized, cx, cy)\n",
    "    return frame\n",
    "\n",
    "# -------------------------------\n",
    "# Webcam\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        lm = results.pose_landmarks.landmark\n",
    "        def get_point(name):\n",
    "            idx = landmark_names[name]\n",
    "            return int(lm[idx].x * w), int(lm[idx].y * h)\n",
    "\n",
    "        # Place bottom first (pant/skirt), then top (shirt/full sleeve)\n",
    "        frame = place_cloth(frame, bottom_img, bottom_type, get_point)\n",
    "        frame = place_cloth(frame, top_img, top_type, get_point)\n",
    "\n",
    "    cv2.imshow(\"Virtual Try-On\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(VTON)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
