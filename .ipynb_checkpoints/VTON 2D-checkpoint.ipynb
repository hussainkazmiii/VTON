{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5697731b-83a2-4da5-beb2-90698a82969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in d:\\virtual-tryon\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in d:\\virtual-tryon\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: smplx in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.1.28)\n",
      "Requirement already satisfied: numpy>=1.16.2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from smplx) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.0.1.post2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from smplx) (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\virtual-tryon\\.venv\\lib\\site-packages (from torch>=1.0.1.post2->smplx) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.1.post2->smplx) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jinja2->torch>=1.0.1.post2->smplx) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in d:\\virtual-tryon\\.venv\\lib\\site-packages (4.12.0.88)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trimesh in d:\\virtual-tryon\\.venv\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from trimesh) (2.2.6)\n",
      "Requirement already satisfied: pyrender in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.1.45)\n",
      "Requirement already satisfied: freetype-py in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.5.1)\n",
      "Requirement already satisfied: imageio in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.37.0)\n",
      "Requirement already satisfied: networkx in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (3.5)\n",
      "Requirement already satisfied: numpy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.2.6)\n",
      "Requirement already satisfied: Pillow in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (10.1.0)\n",
      "Requirement already satisfied: pyglet>=1.4.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (2.1.8)\n",
      "Requirement already satisfied: PyOpenGL==3.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (3.1.0)\n",
      "Requirement already satisfied: scipy in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (1.16.1)\n",
      "Requirement already satisfied: six in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (1.17.0)\n",
      "Requirement already satisfied: trimesh in d:\\virtual-tryon\\.venv\\lib\\site-packages (from pyrender) (4.8.1)\n",
      "Requirement already satisfied: matplotlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: pyopengl in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: mediapipe in d:\\virtual-tryon\\.venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: jaxlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.7.1)\n",
      "Requirement already satisfied: matplotlib in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (3.10.6)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in d:\\virtual-tryon\\.venv\\lib\\site-packages (from mediapipe) (0.2.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\virtual-tryon\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from jax->mediapipe) (1.16.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\virtual-tryon\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyopengl in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: pyopengl_accelerate in d:\\virtual-tryon\\.venv\\lib\\site-packages (3.1.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install smplx\n",
    "!pip install opencv-python\n",
    "!pip install trimesh\n",
    "!pip install pyrender\n",
    "!pip install matplotlib\n",
    "!pip install pyopengl\n",
    "!pip install mediapipe\n",
    "!pip install pyopengl pyopengl_accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309def15-b202-4bf3-b6ec-840917084608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching pyrender viewer... (press ESC to quit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Viewer=(width=800, height=800)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import smplx\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "\n",
    "# ========== Load SMPL model ==========\n",
    "MODEL_PATH = \"./SMPL_models\"   # <-- replace with the folder containing smpl.pkl\n",
    "smpl = smplx.SMPL(model_path=MODEL_PATH, gender=\"NEUTRAL\").to(\"cpu\")\n",
    "\n",
    "# Shape and pose parameters\n",
    "betas = torch.zeros([1, 10], device=\"cpu\")\n",
    "body_pose = torch.zeros([1, 69], device=\"cpu\")\n",
    "\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "mesh_pr = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "# ========== Scene ==========\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh_pr)\n",
    "\n",
    "# Add camera\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "camera_pose = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, -0.5],   # move up a bit\n",
    "    [0, 0, 1, 2.5],    # move back a bit\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# Add light\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=np.eye(4))\n",
    "\n",
    "# ========== Viewer ==========\n",
    "print(\"Launching pyrender viewer... (press ESC to quit)\")\n",
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(800, 800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f37e7e2-4f6a-4578-92c6-b6b3917f7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import cv2\n",
    "\n",
    "from smplx import SMPL\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load SMPL model (T-pose)\n",
    "# -------------------------------\n",
    "smpl_model_path = \"./smpl_models\"  # adjust to your path\n",
    "smpl = SMPL(model_path=smpl_model_path, gender='NEUTRAL')\n",
    "\n",
    "# Zero pose & shape → T-pose\n",
    "betas = torch.zeros([1, 10], dtype=torch.float32)\n",
    "body_pose = torch.zeros([1, 69], device=\"cpu\")\n",
    "\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Render SMPL (offscreen)\n",
    "# -------------------------------\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "pyr_mesh = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "scene = pyrender.Scene(bg_color=[255, 255, 255, 255], ambient_light=[0.8, 0.8, 0.8])\n",
    "scene.add(pyr_mesh)\n",
    "\n",
    "# ---- Add Camera ----\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "cam_pose = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0, -0.5],   # move camera up a bit\n",
    "    [0.0, 0.0, 1.0, 2.5],    # move camera away from SMPL\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "scene.add(camera, pose=cam_pose)\n",
    "\n",
    "# ---- Add Light ----\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=cam_pose)\n",
    "\n",
    "# ---- Offscreen Renderer ----\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=512, viewport_height=512)\n",
    "color, depth = renderer.render(scene)\n",
    "renderer.delete()\n",
    "\n",
    "# Convert to OpenCV format\n",
    "smpl_img = cv2.cvtColor(color, cv2.COLOR_RGBA2BGRA)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load 2D shirt\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Define torso region (approx)\n",
    "# -------------------------------\n",
    "shift_up = 88\n",
    "h, w, _ = smpl_img.shape\n",
    "x1, y1 = int(w*0.3), int(h*0.35) - shift_up  # left shoulder\n",
    "x2, y2 = int(w*0.7), int(h*0.65) - shift_up  # right hip\n",
    "\n",
    "sh_h, sh_w = shirt_img.shape[:2]\n",
    "torso_width  = (x2 - x1) \n",
    "torso_height = (y2 - y1)\n",
    "scale = min(torso_width / sh_w, torso_height / sh_h)\n",
    "old_w = int(sh_w * scale)\n",
    "old_h = int(sh_h * scale)\n",
    "\n",
    "shrink_factor = 0.72\n",
    "new_w = int(old_w * shrink_factor)\n",
    "new_h = int(old_h * shrink_factor)\n",
    "\n",
    "\n",
    "resized_shirt = cv2.resize(shirt_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Overlay shirt on SMPL\n",
    "# -------------------------------\n",
    "offset_x = x1 + (torso_width - new_w) // 2\n",
    "offset_y = y1 + (torso_height - new_h) // 2\n",
    "\n",
    "overlay = smpl_img.copy()\n",
    "for y in range(new_h):\n",
    "    for x in range(new_w):\n",
    "        if resized_shirt[y, x, 3] > 0:  # alpha\n",
    "            overlay[offset_y+y, offset_x+x, :3] = resized_shirt[y, x, :3]\n",
    "\n",
    "# -------------------------------\n",
    "# 3b. Load 2D pants\n",
    "# -------------------------------\n",
    "pant_img = cv2.imread(\"./database/cargo.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 4b. Define hip/leg region (approx)\n",
    "# -------------------------------\n",
    "shift_up = 95\n",
    "x1_p, y1_p = int(w*0.35), int(h*0.55) - shift_up # left hip\n",
    "x2_p, y2_p = int(w*0.65), int(h*0.85) - shift_up # right thigh\n",
    "\n",
    "pant_h, pant_w = pant_img.shape[:2]\n",
    "pant_width  = (x2_p - x1_p)\n",
    "pant_height = (y2_p - y1_p)\n",
    "\n",
    "# Make pant a bit wider\n",
    "scale_w = 1.20 * (pant_width / pant_w)  # 20% wider\n",
    "scale_h = pant_height / pant_h         # keep vertical scale the same\n",
    "\n",
    "new_w_p = int(pant_w * scale_w)\n",
    "new_h_p = int(pant_h * scale_h)\n",
    "\n",
    "resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "# shrink_factor = 1.00\n",
    "# new_w_p = int(old_w_p * shrink_factor)\n",
    "# new_h_p = int(old_h_p * shrink_factor)\n",
    "\n",
    "# resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# -------------------------------\n",
    "# 5b. Overlay pants on SMPL\n",
    "# -------------------------------\n",
    "offset_x_p = x1_p + (pant_width - new_w_p) // 2 \n",
    "offset_y_p = y1_p + (pant_height - new_h_p) // 2 + 25\n",
    "\n",
    "for y in range(new_h_p):\n",
    "    for x in range(new_w_p):\n",
    "        if resized_pant[y, x, 3] > 0:  # alpha\n",
    "            overlay[offset_y_p+y, offset_x_p+x, :3] = resized_pant[y, x, :3]\n",
    "\n",
    "# -------------------------------\n",
    "# 6b. Show result\n",
    "# -------------------------------\n",
    "cv2.imshow(\"SMPL + Shirt + Pants\", overlay)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831338e-7ff1-4f20-b460-c4d87dcf302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import cv2\n",
    "from smplx import SMPL\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load SMPL model (T-pose)\n",
    "# -------------------------------\n",
    "smpl_model_path = \"./smpl_models\"\n",
    "smpl = SMPL(model_path=smpl_model_path, gender='NEUTRAL')\n",
    "\n",
    "betas = torch.zeros([1, 10], dtype=torch.float32)\n",
    "body_pose = torch.zeros([1, 69], dtype=torch.float32)  # Default T-pose\n",
    "\n",
    "# SMPL output\n",
    "output = smpl(betas=betas, body_pose=body_pose)\n",
    "vertices = output.vertices[0].detach().cpu().numpy()\n",
    "faces = smpl.faces\n",
    "joints = output.joints[0].detach().cpu().numpy()  # (24,3)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Render SMPL offscreen\n",
    "# -------------------------------\n",
    "mesh = trimesh.Trimesh(vertices, faces, process=False)\n",
    "pyr_mesh = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "scene = pyrender.Scene(bg_color=[255,255,255,255], ambient_light=[0.8,0.8,0.8])\n",
    "scene.add(pyr_mesh)\n",
    "\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi/3.0)\n",
    "# Adjusted camera pose for better alignment\n",
    "cam_pose = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, -1.0, 0.0, 0.0],  # Flipped Y to correct orientation\n",
    "    [0.0, 0.0, 1.0, 3.5],  # Increased Z distance\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "scene.add(camera, pose=cam_pose)\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=cam_pose)\n",
    "\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=512, viewport_height=512)\n",
    "color, _ = renderer.render(scene)\n",
    "renderer.delete()\n",
    "\n",
    "smpl_img = cv2.cvtColor(color, cv2.COLOR_RGBA2BGRA)\n",
    "H, W = smpl_img.shape[:2]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Helper: project 3D point -> 2D\n",
    "# -------------------------------\n",
    "def project_to_image(point_3d, camera_pose, camera, W, H):\n",
    "    point_h = np.append(point_3d, 1)\n",
    "    cam_point = np.linalg.inv(camera_pose) @ point_h\n",
    "    x = cam_point[0] / cam_point[2]\n",
    "    y = cam_point[1] / cam_point[2]\n",
    "    f = 0.5 * H / np.tan(camera.yfov / 2)\n",
    "    u = int(W/2 + x*f)\n",
    "    v = int(H/2 - y*f)\n",
    "    return u, v\n",
    "\n",
    "def clamp(val, min_val, max_val):\n",
    "    return max(min_val, min(val, max_val))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Detect joints\n",
    "# -------------------------------\n",
    "# Use SMPL joints directly for shoulders, hips, knees\n",
    "joint_indices = {\n",
    "    \"left_shoulder\": 16,   # Left shoulder\n",
    "    \"right_shoulder\": 17,  # Right shoulder\n",
    "    \"left_hip\": 1,\n",
    "    \"right_hip\": 2,\n",
    "    \"left_knee\": 4,\n",
    "    \"right_knee\": 5\n",
    "}\n",
    "\n",
    "joint_2d = {}\n",
    "for name, idx in joint_indices.items():\n",
    "    joint_2d[name] = project_to_image(joints[idx], cam_pose, camera, W, H)\n",
    "    # clamp inside image\n",
    "    u, v = joint_2d[name]\n",
    "    joint_2d[name] = (clamp(u,0,W-1), clamp(v,0,H-1))\n",
    "\n",
    "# Colors for visualization\n",
    "joint_colors = {\n",
    "    \"left_shoulder\": (255,0,0),    # Red for left shoulder\n",
    "    \"right_shoulder\": (0,0,255),   # Blue for right shoulder\n",
    "    \"left_hip\": (255,0,255),       # Purple for left hip\n",
    "    \"right_hip\": (0,128,255),      # Teal for right hip\n",
    "    \"left_knee\": (128,0,128),\n",
    "    \"right_knee\": (128,128,0)\n",
    "}\n",
    "\n",
    "# Draw joints\n",
    "for name, (u,v) in joint_2d.items():\n",
    "    cv2.circle(smpl_img, (u,v), 6, joint_colors[name], -1)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Load clothing images\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "pant_img  = cv2.imread(\"./database/cargo.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Auto-fit shirt\n",
    "# -------------------------------\n",
    "l_sh = joint_2d[\"left_shoulder\"]\n",
    "r_sh = joint_2d[\"right_shoulder\"]\n",
    "l_hip = joint_2d[\"left_hip\"]\n",
    "r_hip = joint_2d[\"right_hip\"]\n",
    "\n",
    "torso_width  = max(r_sh[0] - l_sh[0], 1)\n",
    "torso_height = max(r_hip[1] - l_sh[1], 1)\n",
    "\n",
    "sh_h, sh_w = shirt_img.shape[:2]\n",
    "scale_sh = max(min(torso_width/sh_w, torso_height/sh_h), 0.01)\n",
    "resized_sh = cv2.resize(shirt_img, (int(sh_w*scale_sh), int(sh_h*scale_sh)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "offset_x = l_sh[0]\n",
    "offset_y = l_sh[1]\n",
    "\n",
    "overlay_img = smpl_img.copy()\n",
    "for y in range(resized_sh.shape[0]):\n",
    "    for x in range(resized_sh.shape[1]):\n",
    "        if resized_sh[y,x,3] > 0:\n",
    "            py = clamp(offset_y+y,0,H-1)\n",
    "            px = clamp(offset_x+x,0,W-1)\n",
    "            overlay_img[py, px, :3] = resized_sh[y,x,:3]\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Auto-fit pants\n",
    "# -------------------------------\n",
    "l_hip = joint_2d[\"left_hip\"]\n",
    "r_hip = joint_2d[\"right_hip\"]\n",
    "l_knee = joint_2d[\"left_knee\"]\n",
    "r_knee = joint_2d[\"right_knee\"]\n",
    "\n",
    "pant_width  = max(r_hip[0] - l_hip[0], 1)\n",
    "pant_height = max(((l_knee[1]+r_knee[1])//2) - l_hip[1], 1)\n",
    "\n",
    "pant_h, pant_w = pant_img.shape[:2]\n",
    "scale_pant_w = max(1.05 * (pant_width/pant_w), 0.01)\n",
    "scale_pant_h = max(pant_height/pant_h, 0.01)\n",
    "new_w_p = int(pant_w * scale_pant_w)\n",
    "new_h_p = int(pant_h * scale_pant_h)\n",
    "resized_pant = cv2.resize(pant_img, (new_w_p, new_h_p), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "offset_x_p = l_hip[0]\n",
    "offset_y_p = l_hip[1]\n",
    "\n",
    "for y in range(new_h_p):\n",
    "    for x in range(new_w_p):\n",
    "        if resized_pant[y,x,3] > 0:\n",
    "            py = clamp(offset_y_p+y,0,H-1)\n",
    "            px = clamp(offset_x_p+x,0,W-1)\n",
    "            overlay_img[py, px, :3] = resized_pant[y,x,:3]\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Show final result\n",
    "# -------------------------------\n",
    "cv2.imshow(\"SMPL + Auto Shirt + Auto Pants\", overlay_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d90342-b389-4e0b-9f7b-9237a32adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load 2D Shirt & Pant Images with alpha channel\n",
    "# -------------------------------\n",
    "shirt_img = cv2.imread(\"./database/shirt2.png\", cv2.IMREAD_UNCHANGED)\n",
    "pant_img = cv2.imread(\"./database/cargo.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "sh_h, sh_w = shirt_img.shape[:2]\n",
    "pant_h, pant_w = pant_img.shape[:2]\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Initialize Mediapipe Pose\n",
    "# -------------------------------\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    enable_segmentation=False,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Open Webcam\n",
    "# -------------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        lm = results.pose_landmarks.landmark\n",
    "\n",
    "        # -------------------------------\n",
    "        # ✅ Shirt Code (unchanged)\n",
    "        # -------------------------------\n",
    "        keypoints = [mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "                     mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "                     mp_pose.PoseLandmark.LEFT_HIP,\n",
    "                     mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "\n",
    "        if not any(lm[i].visibility < 0.5 for i in keypoints):\n",
    "            pts_dst = np.array([\n",
    "                [int(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.RIGHT_HIP].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.RIGHT_HIP].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.LEFT_HIP].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.LEFT_HIP].y * h)]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            expand_factor_w = 0.45\n",
    "            expand_factor_h = 0.16\n",
    "\n",
    "            torso_width = np.linalg.norm(pts_dst[1] - pts_dst[0])\n",
    "            torso_height = np.linalg.norm(pts_dst[3] - pts_dst[0])\n",
    "\n",
    "            vec_top = pts_dst[1] - pts_dst[0]\n",
    "            vec_top_norm = vec_top / np.linalg.norm(vec_top)\n",
    "            pts_dst[0] = pts_dst[0] - vec_top_norm * expand_factor_w * torso_width\n",
    "            pts_dst[1] = pts_dst[1] + vec_top_norm * expand_factor_w * torso_width\n",
    "\n",
    "            vec_bottom = pts_dst[2] - pts_dst[3]\n",
    "            vec_bottom_norm = vec_bottom / np.linalg.norm(vec_bottom)\n",
    "            pts_dst[3] = pts_dst[3] - vec_bottom_norm * expand_factor_w * torso_width\n",
    "            pts_dst[2] = pts_dst[2] + vec_bottom_norm * expand_factor_w * torso_width\n",
    "\n",
    "            pts_dst[0][1] -= expand_factor_h * torso_height\n",
    "            pts_dst[1][1] -= expand_factor_h * torso_height\n",
    "            pts_dst[2][1] += expand_factor_h * torso_height\n",
    "            pts_dst[3][1] += expand_factor_h * torso_height\n",
    "\n",
    "            pts_src = np.array([\n",
    "                [0, 0],\n",
    "                [sh_w - 1, 0],\n",
    "                [sh_w - 1, sh_h - 1],\n",
    "                [0, sh_h - 1]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            M = cv2.getPerspectiveTransform(pts_src, pts_dst)\n",
    "            warped_shirt = cv2.warpPerspective(shirt_img, M, (w, h), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "            alpha = warped_shirt[:, :, 3] / 255.0\n",
    "            alpha_inv = 1.0 - alpha\n",
    "            for c in range(3):\n",
    "                frame[:, :, c] = alpha * warped_shirt[:, :, c] + alpha_inv * frame[:, :, c]\n",
    "\n",
    "        # -------------------------------\n",
    "        # 👖 Pants Code (resized bigger & wider)\n",
    "        # -------------------------------\n",
    "        pant_points = [mp_pose.PoseLandmark.LEFT_HIP,\n",
    "                       mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "                       mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "                       mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "\n",
    "        if not any(lm[i].visibility < 0.5 for i in pant_points):\n",
    "            pants_dst = np.array([\n",
    "                [int(lm[mp_pose.PoseLandmark.LEFT_HIP].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.LEFT_HIP].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.RIGHT_HIP].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.RIGHT_HIP].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.RIGHT_ANKLE].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.RIGHT_ANKLE].y * h)],\n",
    "                [int(lm[mp_pose.PoseLandmark.LEFT_ANKLE].x * w),\n",
    "                 int(lm[mp_pose.PoseLandmark.LEFT_ANKLE].y * h)]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            expand_factor_w_pants = 0.70   # wider\n",
    "            expand_factor_h_pants = 0.17   # longer\n",
    "\n",
    "            pants_width = np.linalg.norm(pants_dst[1] - pants_dst[0])\n",
    "            pants_height = np.linalg.norm(pants_dst[3] - pants_dst[0])\n",
    "\n",
    "            vec_top_p = pants_dst[1] - pants_dst[0]\n",
    "            vec_top_p_norm = vec_top_p / np.linalg.norm(vec_top_p)\n",
    "            pants_dst[0] = pants_dst[0] - vec_top_p_norm * expand_factor_w_pants * pants_width\n",
    "            pants_dst[1] = pants_dst[1] + vec_top_p_norm * expand_factor_w_pants * pants_width\n",
    "\n",
    "            vec_bottom_p = pants_dst[2] - pants_dst[3]\n",
    "            vec_bottom_p_norm = vec_bottom_p / np.linalg.norm(vec_bottom_p)\n",
    "            pants_dst[3] = pants_dst[3] - vec_bottom_p_norm * expand_factor_w_pants * pants_width\n",
    "            pants_dst[2] = pants_dst[2] + vec_bottom_p_norm * expand_factor_w_pants * pants_width\n",
    "\n",
    "            pants_dst[0][1] -= expand_factor_h_pants * pants_height\n",
    "            pants_dst[1][1] -= expand_factor_h_pants * pants_height\n",
    "            pants_dst[2][1] += expand_factor_h_pants * pants_height\n",
    "            pants_dst[3][1] += expand_factor_h_pants * pants_height\n",
    "\n",
    "            pts_src_pants = np.array([\n",
    "                [0, 0],\n",
    "                [pant_w - 1, 0],\n",
    "                [pant_w - 1, pant_h - 1],\n",
    "                [0, pant_h - 1]\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            M_pants = cv2.getPerspectiveTransform(pts_src_pants, pants_dst)\n",
    "            warped_pants = cv2.warpPerspective(pant_img, M_pants, (w, h), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "            alpha_p = warped_pants[:, :, 3] / 255.0\n",
    "            alpha_inv_p = 1.0 - alpha_p\n",
    "            for c in range(3):\n",
    "                frame[:, :, c] = alpha_p * warped_pants[:, :, c] + alpha_inv_p * frame[:, :, c]\n",
    "\n",
    "    # -------------------------------\n",
    "    # Show result\n",
    "    # -------------------------------\n",
    "    cv2.imshow(\"AR 2D Shirt + Pant Try-On\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(VTON)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
